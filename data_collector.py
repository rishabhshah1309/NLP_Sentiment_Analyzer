"""
Robust Multi-Platform Data Collection for Sports Sponsorship Analysis
ISBA 2411 - Rishabh Shah

This version includes fallbacks and demo data to ensure your project always works
"""

import pandas as pd
import numpy as np
import requests
import time
from datetime import datetime, timedelta
import re
from typing import List, Dict
import logging
import random

# Social media libraries
try:
    import tweepy
    import praw
    import instaloader
except ImportError as e:
    print(f"Some social media libraries missing: {e}")
    print("Install with: pip install tweepy praw instaloader")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SponsorshipDataCollector:
    """Collect sponsorship data from multiple social media platforms with robust fallbacks"""
    
    def __init__(self, config):
        self.config = config
        self.all_data = []
        
    def collect_twitter_data(self):
        """Selenium-based multi-site scraping"""
        from selenium_scraper import collect_all_sites_data
        
        logger.info("üï∑Ô∏è Using Selenium multi-site scraping...")
        
        # This scrapes ALL sites and returns everything
        all_data = collect_all_sites_data(self.config)
        
        # Filter for Twitter data specifically
        twitter_data = [item for item in all_data if item['platform'] == 'twitter']
        
        # Save all data for later analysis
        if all_data:
            import pandas as pd
            df = pd.DataFrame(all_data)
            df.to_csv('multi_site_sponsorship_data.csv', index=False)
            logger.info(f"üíæ Saved {len(all_data)} items from all sites")
        
        return twitter_data

    def _is_sports_related_advanced(self, text, context_annotations=None):
        """
        Advanced sports detection using text and Twitter's context annotations
        """
        if not text:
            return False
        
        text_lower = text.lower()
        
        # Comprehensive sports keywords
        sports_keywords = [
            # Sports
            'football', 'soccer', 'basketball', 'baseball', 'hockey', 'tennis',
            'cricket', 'rugby', 'golf', 'nascar', 'f1', 'formula 1',
            
            # Teams and organizations
            'team', 'player', 'league', 'championship', 'tournament', 'match',
            'game', 'stadium', 'arena', 'club', 'fc', 'united', 'city',
            
            # Major leagues
            'premier league', 'nba', 'nfl', 'mlb', 'mls', 'champions league',
            'la liga', 'serie a', 'bundesliga', 'ligue 1', 'uefa', 'fifa',
            
            # Sponsorship related
            'nike', 'adidas', 'emirates', 'jersey', 'kit', 'sponsor',
            'partnership', 'deal', 'naming rights', 'official partner'
        ]
        
        # Check text content
        text_sports_related = any(keyword in text_lower for keyword in sports_keywords)
        
        # Check Twitter's context annotations (these are very accurate for Academic API)
        context_sports_related = False
        if context_annotations:
            for annotation in context_annotations:
                if 'domain' in annotation:
                    domain = annotation['domain'].get('name', '').lower()
                    if any(sport_term in domain for sport_term in ['sport', 'athlete', 'team', 'league', 'game']):
                        context_sports_related = True
                        break
                
                if 'entity' in annotation:
                    entity = annotation['entity'].get('name', '').lower()
                    if any(sport_term in entity for sport_term in ['fc', 'united', 'city', 'athletic', 'sports']):
                        context_sports_related = True
                        break
        
        return text_sports_related or context_sports_related
    
    def _generate_demo_twitter_data(self):
        """Generate realistic demo Twitter data for demonstration"""
        demo_tweets = [
            {
                'text': "Excited about the new @Nike jersey deal with Manchester United! The design looks amazing and the partnership makes sense. #MUFC #Nike",
                'sentiment_hint': 'positive'
            },
            {
                'text': "Really disappointed with the Emirates Stadium naming rights. The old name had so much history and character. #Arsenal",
                'sentiment_hint': 'negative'
            },
            {
                'text': "The new @adidas kit supplier deal with Real Madrid is worth ‚Ç¨1.1 billion over 10 years. Massive investment in football! #RealMadrid",
                'sentiment_hint': 'positive'
            },
            {
                'text': "Another corporate sponsor taking over our beloved stadium name. When will this commercialization of football end?",
                'sentiment_hint': 'negative'
            },
            {
                'text': "Fair play to @Lakers for partnering with a local LA business. At least it supports the community while generating revenue.",
                'sentiment_hint': 'positive'
            },
            {
                'text': "The jersey patches are getting ridiculous. Soon players will look like NASCAR drivers with all these sponsor logos.",
                'sentiment_hint': 'negative'
            },
            {
                'text': "Great to see @NBA partnering with sustainable brands. Sports organizations should lead by example on environmental issues.",
                'sentiment_hint': 'positive'
            },
            {
                'text': "The new naming rights deal brings much needed revenue to the club. Smart business decision for long-term stability.",
                'sentiment_hint': 'positive'
            },
            {
                'text': "These corporate partnerships are ruining the soul of sports. Everything is about money now, not the fans or tradition.",
                'sentiment_hint': 'negative'
            },
            {
                'text': "Impressed with how @premierleague handles sponsor integration. It feels natural and doesn't overwhelm the viewing experience.",
                'sentiment_hint': 'positive'
            }
        ]
        
        twitter_data = []
        base_date = datetime.now() - timedelta(days=15)
        
        for i, tweet_template in enumerate(demo_tweets):
            twitter_data.append({
                'platform': 'twitter',
                'id': f'demo_tweet_{i+1}',
                'text': tweet_template['text'],
                'username': f'sports_fan_{i+1}',
                'created_date': base_date + timedelta(days=i),
                'likes': random.randint(5, 500),
                'retweets': random.randint(1, 100),
                'replies': random.randint(0, 50),
                'engagement': random.randint(10, 600),
                'search_term': 'demo_data'
            })
        
        return twitter_data
    
    def collect_reddit_data(self):
        """Collect Reddit data"""
        logger.info("Collecting Reddit data...")
        reddit_data = []
        
        if not self.config.REDDIT_CLIENT_ID or self.config.REDDIT_CLIENT_ID == '':
            logger.info("Reddit credentials not configured - generating demo data")
            return self._generate_demo_reddit_data()
        
        try:
            reddit = praw.Reddit(
                client_id=self.config.REDDIT_CLIENT_ID,
                client_secret=self.config.REDDIT_CLIENT_SECRET,
                user_agent=self.config.REDDIT_USER_AGENT
            )
            
            # Test Reddit connection
            reddit.user.me()
            logger.info("Reddit API connection successful")
            
            for subreddit_name in self.config.REDDIT_SUBREDDITS[:3]:
                logger.info(f"Searching r/{subreddit_name}")
                
                try:
                    subreddit = reddit.subreddit(subreddit_name)
                    
                    for term in self.config.SPONSORSHIP_KEYWORDS[:2]:
                        try:
                            for submission in subreddit.search(term, time_filter='month', limit=5):
                                reddit_data.append({
                                    'platform': 'reddit',
                                    'id': submission.id,
                                    'text': f"{submission.title} {submission.selftext}".strip(),
                                    'username': f"reddit_user_{submission.id[:8]}",
                                    'created_date': datetime.fromtimestamp(submission.created_utc),
                                    'likes': submission.score,
                                    'retweets': 0,
                                    'replies': submission.num_comments,
                                    'engagement': submission.score + submission.num_comments,
                                    'search_term': term,
                                    'subreddit': subreddit_name
                                })
                            
                            time.sleep(1)
                        except Exception as e:
                            logger.warning(f"Error searching r/{subreddit_name} for {term}: {e}")
                            continue
                    
                    time.sleep(2)
                    
                except Exception as e:
                    logger.warning(f"Error accessing r/{subreddit_name}: {e}")
                    continue
                    
        except Exception as e:
            logger.warning(f"Reddit collection failed: {e}")
            logger.info("Generating demo Reddit data...")
            return self._generate_demo_reddit_data()
        
        if not reddit_data:
            logger.info("No Reddit data collected - generating demo data")
            return self._generate_demo_reddit_data()
        
        logger.info(f"Collected {len(reddit_data)} Reddit posts")
        return reddit_data
    
    def _generate_demo_reddit_data(self):
        """Generate realistic demo Reddit data"""
        demo_posts = [
            {
                'text': "Discussion: New Emirates sponsorship deal with Arsenal. Thoughts on how this affects the club's financial future and fan experience? The deal is reportedly worth ¬£200M over 5 years.",
                'subreddit': 'soccer'
            },
            {
                'text': "Lakers unveil new jersey sponsor partnership. The patch placement looks clean and the brand alignment makes sense for LA market.",
                'subreddit': 'nba'
            },
            {
                'text': "Opinion: Stadium naming rights deals are getting out of hand. Every venue is now 'SomeCompany Arena' and it's killing the tradition.",
                'subreddit': 'sports'
            },
            {
                'text': "Analysis of NFL jersey sponsorship revenue vs fan sentiment. Interesting data showing correlation between sponsor choice and fan acceptance.",
                'subreddit': 'nfl'
            },
            {
                'text': "Manchester United's Nike deal extension: Good business or selling soul? Let's discuss the pros and cons of this massive partnership.",
                'subreddit': 'soccer'
            }
        ]
        
        reddit_data = []
        base_date = datetime.now() - timedelta(days=20)
        
        for i, post in enumerate(demo_posts):
            reddit_data.append({
                'platform': 'reddit',
                'id': f'demo_reddit_{i+1}',
                'text': post['text'],
                'username': f'reddit_user_{i+1}',
                'created_date': base_date + timedelta(days=i*2),
                'likes': random.randint(10, 200),
                'retweets': 0,
                'replies': random.randint(5, 50),
                'engagement': random.randint(15, 250),
                'search_term': 'demo_data',
                'subreddit': post['subreddit']
            })
        
        return reddit_data
    
    def collect_instagram_data(self):
        """Collect Instagram data (simplified for demo)"""
        logger.info("Collecting Instagram data...")
        
        # Generate demo Instagram data (Instagram scraping is complex and often blocked)
        logger.info("Generating demo Instagram data...")
        
        demo_posts = [
            {
                'text': "üèÜ Excited to announce our new partnership with @nike! This collaboration represents our commitment to excellence both on and off the field. #Partnership #Nike #Excellence",
            },
            {
                'text': "New stadium, new name, new era! Welcome to @emirates Stadium - home of champions. The future looks bright! ‚öΩ #Emirates #NewEra #Football",
            },
            {
                'text': "Behind the scenes of our @adidas photoshoot! The new kit design is absolutely stunning. Can't wait for you all to see it! üì∏ #Adidas #NewKit #BehindTheScenes",
            }
        ]
        
        instagram_data = []
        base_date = datetime.now() - timedelta(days=10)
        
        for i, post in enumerate(demo_posts):
            instagram_data.append({
                'platform': 'instagram',
                'id': f'demo_instagram_{i+1}',
                'text': post['text'],
                'username': f'official_team_{i+1}',
                'created_date': base_date + timedelta(days=i*3),
                'likes': random.randint(1000, 50000),
                'retweets': 0,
                'replies': random.randint(50, 500),
                'engagement': random.randint(1500, 55000),
                'search_term': 'demo_data'
            })
        
        logger.info(f"Generated {len(instagram_data)} Instagram posts")
        return instagram_data
    
    def _is_sports_related(self, text):
        """Check if text is sports-related"""
        if not text:
            return False
        
        text_lower = text.lower()
        sports_keywords = [
            'football', 'soccer', 'basketball', 'baseball', 'hockey', 'tennis',
            'team', 'player', 'league', 'championship', 'tournament', 'match',
            'game', 'stadium', 'arena', 'club', 'fc', 'united', 'city',
            'premier league', 'nba', 'nfl', 'mlb', 'mls', 'nike', 'adidas',
            'jersey', 'kit', 'sponsor', 'partnership'
        ]
        
        return any(keyword in text_lower for keyword in sports_keywords)
    
    def collect_all_data(self):
        """Collect data from all platforms with robust error handling"""
        logger.info("="*50)
        logger.info("üöÄ Starting Multi-Platform Data Collection")
        logger.info("="*50)
        
        all_data = []
        
        # Collect from each platform
        try:
            twitter_data = self.collect_twitter_data()
            all_data.extend(twitter_data)
            logger.info(f"‚úÖ Twitter: {len(twitter_data)} posts")
        except Exception as e:
            logger.error(f"‚ùå Twitter collection failed: {e}")
        
        try:
            reddit_data = self.collect_reddit_data()
            all_data.extend(reddit_data)
            logger.info(f"‚úÖ Reddit: {len(reddit_data)} posts")
        except Exception as e:
            logger.error(f"‚ùå Reddit collection failed: {e}")
        
        try:
            instagram_data = self.collect_instagram_data()
            all_data.extend(instagram_data)
            logger.info(f"‚úÖ Instagram: {len(instagram_data)} posts")
        except Exception as e:
            logger.error(f"‚ùå Instagram collection failed: {e}")
        
        if not all_data:
            logger.warning("‚ö†Ô∏è No data collected from any platform! Using comprehensive demo dataset...")
            all_data = self._generate_comprehensive_demo_data()
        
        # Convert to DataFrame and clean
        df = pd.DataFrame(all_data)
        
        if len(df) > 0:
            # Standardize data
            df['created_date'] = pd.to_datetime(df['created_date'])
            df['text'] = df['text'].astype(str)
            df['text_length'] = df['text'].str.len()
            
            # Filter out very short posts
            df = df[df['text_length'] >= self.config.MIN_TEXT_LENGTH]
            
            # Remove duplicates
            df = df.drop_duplicates(subset=['text'])
            
            logger.info("="*50)
            logger.info(f"üìä COLLECTION SUMMARY")
            logger.info("="*50)
            logger.info(f"Total unique posts: {len(df)}")
            
            platform_counts = df['platform'].value_counts()
            for platform, count in platform_counts.items():
                percentage = count / len(df) * 100
                logger.info(f"  {platform.title()}: {count} posts ({percentage:.1f}%)")
            
            logger.info(f"Date range: {df['created_date'].min().date()} to {df['created_date'].max().date()}")
            logger.info("="*50)
        
        return df
    
    def _generate_comprehensive_demo_data(self):
        """Generate a comprehensive demo dataset for analysis"""
        logger.info("Generating comprehensive demo dataset for analysis...")
        
        demo_data = []
        
        # Twitter-style posts
        twitter_posts = [
            "Absolutely love the new @Nike partnership with Manchester United! The jersey design is clean and the brand fits perfectly. #MUFC #Nike",
            "The Emirates Stadium naming rights deal was the beginning of the end for football tradition. Money over heritage every time. #Arsenal",
            "Smart move by @Lakers partnering with a tech company. Basketball and innovation go hand in hand. #Lakers #Innovation",
            "These jersey sponsors are getting out of control. Soon players will look like walking billboards. #Soccer #Commercialization",
            "Great to see @NBA choosing sustainable partners. Sports should lead on environmental responsibility. #NBA #Sustainability",
            "The new Allianz Arena name just doesn't have the same ring as the old one. Some things shouldn't be sold. #FCBayern",
            "Excited about the @adidas Real Madrid renewal! 10 years of excellence ahead. Hala Madrid! #RealMadrid #Adidas",
            "Stadium naming rights bring much needed revenue to clubs. It's just business in modern football. #ModernFootball",
            "The @PremierLeague sponsor integration is done tastefully. Other leagues should take notes. #PremierLeague",
            "Corporate sponsors are ruining the authenticity of sports. Everything is about profit now. #SportsAuthenticity"
        ]
        
        # Reddit-style posts  
        reddit_posts = [
            "Analysis: How the Emirates sponsorship deal changed Arsenal's financial landscape. The ¬£200M investment allowed for better player acquisitions and stadium improvements, but fans still debate whether it was worth losing the traditional name.",
            "Discussion: NBA jersey sponsors vs European football. The NBA's approach with small patches seems more tasteful than the large front-of-shirt sponsors in soccer. What do you think works better?",
            "Opinion: Stadium naming rights deals are necessary evil. Yes, it hurts tradition, but the revenue allows teams to compete at the highest level. Sometimes business decisions are just reality.",
            "Data analysis: Fan sentiment vs sponsorship revenue correlation. Interesting patterns showing that successful sponsor partnerships actually improve fan satisfaction over time when done right.",
            "Question: Which sport handles sponsorship integration best? Comparing NFL, NBA, Premier League, and other major leagues in terms of fan acceptance and aesthetic appeal."
        ]
        
        # Instagram-style posts
        instagram_posts = [
            "üèÜ Proud to announce our new partnership with @nike! This collaboration represents excellence, innovation, and our shared commitment to pushing boundaries. Together, we're writing the next chapter of sporting history. #Partnership #Nike #Excellence #Innovation",
            "‚ú® Behind the scenes of our @adidas photoshoot! The attention to detail in every stitch, every design element, every fabric choice - this is what championship-level partnership looks like. #Adidas #BehindTheScenes #NewKit #Craftsmanship",
            "üåü Welcome to our new home sponsor! This partnership goes beyond business - it's about building community, supporting local initiatives, and creating lasting impact. #Community #Partnership #Impact #Home"
        ]
        
        # Generate varied data
        base_date = datetime.now() - timedelta(days=30)
        
        # Add Twitter data
        for i, text in enumerate(twitter_posts):
            demo_data.append({
                'platform': 'twitter',
                'id': f'demo_tw_{i+1}',
                'text': text,
                'username': f'sports_fan_{i+1}',
                'created_date': base_date + timedelta(days=i*2),
                'likes': random.randint(10, 1000),
                'retweets': random.randint(5, 200),
                'replies': random.randint(2, 100),
                'engagement': random.randint(20, 1300),
                'search_term': 'demo_comprehensive'
            })
        
        # Add Reddit data
        for i, text in enumerate(reddit_posts):
            demo_data.append({
                'platform': 'reddit',
                'id': f'demo_rd_{i+1}',
                'text': text,
                'username': f'reddit_analyst_{i+1}',
                'created_date': base_date + timedelta(days=i*3),
                'likes': random.randint(50, 500),
                'retweets': 0,
                'replies': random.randint(20, 200),
                'engagement': random.randint(70, 700),
                'search_term': 'demo_comprehensive'
            })
        
        # Add Instagram data
        for i, text in enumerate(instagram_posts):
            demo_data.append({
                'platform': 'instagram',
                'id': f'demo_ig_{i+1}',
                'text': text,
                'username': f'official_account_{i+1}',
                'created_date': base_date + timedelta(days=i*5),
                'likes': random.randint(5000, 50000),
                'retweets': 0,
                'replies': random.randint(200, 2000),
                'engagement': random.randint(5500, 55000),
                'search_term': 'demo_comprehensive'
            })
        
        logger.info(f"Generated {len(demo_data)} comprehensive demo posts")
        return demo_data

def collect_sponsorship_data(config):
    """Main function to collect sponsorship data with robust error handling"""
    collector = SponsorshipDataCollector(config)
    return collector.collect_all_data()